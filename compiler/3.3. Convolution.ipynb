{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(X, ph, pw, val=0):\n",
    "    assert len(X.shape) >= 2\n",
    "    nh,nw = X.shape[-2],X.shape[-1]\n",
    "    return te.compute(\n",
    "        (*X.shape[0:-2],nh+ph*2,nw+pw*2),\n",
    "        lambda *i:te.if_then_else(\n",
    "            te.any(i[-2]<ph, i[-2]>=nh+ph, i[-1]<pw, i[-1]>=nw+pw),\n",
    "            val,X[i[:-2]+(i[-2]-ph,i[-1]-pw)]),name='PaddedX')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=te.placeholder((2,3,4))\n",
    "B=padding(A,1,2)\n",
    "s=te.create_schedule(B.op)\n",
    "mod = tvm.build(s,[A,B])\n",
    "\n",
    "a=tvm.nd.array(np.ones((2,3,4),dtype='float32'))\n",
    "b=tvm.nd.array(np.empty((2,5,8),dtype='float32'))\n",
    "mod(a,b)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_out_size(n,k,p,s):\n",
    "    return (n-k+2*p)//s + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(oc,ic,nh,nw,kh,kw,ph=0,pw=0,sh=0,sw=1):\n",
    "    \"\"\"Convolution\n",
    "    oc, ic : output and input channels\n",
    "    nh, nw : input width and height\n",
    "    kh, kw : kernel width and height\n",
    "    ph, pw : height and width padding sizes, default 0\n",
    "    sh, sw : height and width strides, default 1\n",
    "    \"\"\"\n",
    "    ric=te.reduce_axis((0,ic),name='ric')\n",
    "    rkh=te.reduce_axis((0,kh),name='rkh')\n",
    "    rkw=te.reduce_axis((0,kw),name='rkw')\n",
    "    \n",
    "    oh = conv_out_size(nh,kh,ph,sh)\n",
    "    ow = conv_out_size(nw,kw,pw,sw)\n",
    "    \n",
    "    X=te.placeholder((ic,nh,nw),name='X')\n",
    "    K=te.placeholder((oc,ic,kh,kw),name='K')\n",
    "    paddedX = padding(X,ph,pw) if ph *pw !=0 else X\n",
    "    Y = te.compute(\n",
    "        (oc,oh,ow),\n",
    "        lambda c,i,j:te.sum(\n",
    "            paddedX[ric,i*sh+rkh,j*sw+rkw] * K[c,ric,rkh,rkw],\n",
    "            axis=[ric,rkh,rkw]),name='Y')\n",
    "    return X,K,Y,paddedX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_data(oc,ic,n,k,p=0,s=1,constructor=None):\n",
    "    np.random.seed(0)\n",
    "    data = np.random.normal(size=(ic,n,n)).astype('float32')\n",
    "    weight = np.random.normal(size=(oc,ic,k,k)).astype('float32')\n",
    "    on = conv_out_size(n,k,p,s)\n",
    "    out = np.empty((oc,on,on), dtype='float32')\n",
    "    if constructor:\n",
    "        data, weight, out = (constructor(x) for x in [data, weight, out])\n",
    "    return data,weight,out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oc,ic,n,k,p,s = 4,6,12,3,1,1\n",
    "X,K,Y,_ = conv(oc,ic,n,n,k,k,p,p,s,s)\n",
    "sch = te.create_schedule(Y.op)\n",
    "mod = tvm.build(sch,[X,K,Y])\n",
    "# print(tvm.lower(sch,[X,K,Y], simple_mode=True))\n",
    "\n",
    "data, weight, out = get_conv_data(oc, ic, n, k, p, s, tvm.nd.array)\n",
    "mod(data, weight, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "def get_conv_data_mxnet(oc, ic, n, k, p, s, ctx='cpu'):\n",
    "    ctx = getattr(mx, ctx)()\n",
    "    data, weight, out = get_conv_data(oc, ic, n, k, p, s,\n",
    "                                      lambda x: mx.nd.array(x, ctx=ctx))\n",
    "    data, out = data.expand_dims(axis=0), out.expand_dims(axis=0)\n",
    "    bias = mx.nd.zeros(out.shape[1], ctx=ctx)\n",
    "    return data, weight, bias, out\n",
    "\n",
    "def conv_mxnet(data, weight, bias, out, k, p, s):\n",
    "    mx.nd.Convolution(data, weight, bias, kernel=(k,k), stride=(s,s),\n",
    "                      pad=(p,p), num_filter=out.shape[1], out=out)\n",
    "\n",
    "data, weight, bias, out_mx = get_conv_data_mxnet(oc, ic, n, k, p, s)\n",
    "conv_mxnet(data, weight, bias, out_mx, k, p, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(out_mx[0].asnumpy(), out.asnumpy(), atol=1e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
